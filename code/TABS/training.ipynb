{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1NSUPZGEqNIl5Q22MW7MLZS3lIMNWbWrU","authorship_tag":"ABX9TyPN5DdZEv3nNk7z+eNM5D/p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6lp-T7Tco4tA","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1735740714457,"user_tz":-60,"elapsed":8115,"user":{"displayName":"Mahdi Islam","userId":"09138204596823341323"}},"outputId":"534edbd0-1522-48e4-ff7f-2da831f5b13f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting monai\n","  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n","Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: monai\n","Successfully installed monai-1.4.0\n","Collecting torchmetrics\n","  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n","Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n","Installing collected packages: lightning-utilities, torchmetrics\n","Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.1\n"]}],"source":["# Install necessary libraries\n","!pip install monai torch torchvision\n","!pip install torchmetrics"]},{"cell_type":"code","source":["!pip install nibabel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"TmYBlj1csIPp","executionInfo":{"status":"ok","timestamp":1735599589328,"user_tz":-60,"elapsed":3516,"user":{"displayName":"Mahdi Islam","userId":"09138204596823341323"}},"outputId":"7e7f9cad-48eb-4cf2-a592-636ced28b337"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (5.3.2)\n","Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.10/dist-packages (from nibabel) (6.4.5)\n","Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.26.4)\n","Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from nibabel) (24.2)\n","Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.10/dist-packages (from nibabel) (4.12.2)\n"]}]},{"cell_type":"code","source":["!unzip \"/content/drive/MyDrive/MAIA_Work/Semester_3/MISA/MISA_Project/TABS.zip\" -d /content/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"wmN4meZIxgQJ","executionInfo":{"status":"ok","timestamp":1735566500508,"user_tz":-60,"elapsed":1363,"user":{"displayName":"Mahdi Islam","userId":"09138204596823341323"}},"outputId":"dadd4062-f93d-48af-edb8-fa7a428d2b69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/MAIA_Work/Semester_3/MISA/MISA_Project/TABS.zip\n","   creating: /content/TABS/.git/\n","  inflating: /content/TABS/.git/config  \n","  inflating: /content/TABS/.git/description  \n"," extracting: /content/TABS/.git/HEAD  \n","   creating: /content/TABS/.git/hooks/\n","  inflating: /content/TABS/.git/hooks/applypatch-msg.sample  \n","  inflating: /content/TABS/.git/hooks/commit-msg.sample  \n","  inflating: /content/TABS/.git/hooks/fsmonitor-watchman.sample  \n","  inflating: /content/TABS/.git/hooks/post-update.sample  \n","  inflating: /content/TABS/.git/hooks/pre-applypatch.sample  \n","  inflating: /content/TABS/.git/hooks/pre-commit.sample  \n","  inflating: /content/TABS/.git/hooks/pre-merge-commit.sample  \n","  inflating: /content/TABS/.git/hooks/prepare-commit-msg.sample  \n","  inflating: /content/TABS/.git/hooks/pre-push.sample  \n","  inflating: /content/TABS/.git/hooks/pre-rebase.sample  \n","  inflating: /content/TABS/.git/hooks/pre-receive.sample  \n","  inflating: /content/TABS/.git/hooks/push-to-checkout.sample  \n","  inflating: /content/TABS/.git/hooks/update.sample  \n","  inflating: /content/TABS/.git/index  \n","   creating: /content/TABS/.git/info/\n","  inflating: /content/TABS/.git/info/exclude  \n","   creating: /content/TABS/.git/logs/\n","  inflating: /content/TABS/.git/logs/HEAD  \n","   creating: /content/TABS/.git/logs/refs/\n","   creating: /content/TABS/.git/logs/refs/heads/\n","  inflating: /content/TABS/.git/logs/refs/heads/main  \n","   creating: /content/TABS/.git/logs/refs/remotes/\n","   creating: /content/TABS/.git/logs/refs/remotes/origin/\n","  inflating: /content/TABS/.git/logs/refs/remotes/origin/HEAD  \n","   creating: /content/TABS/.git/objects/\n","   creating: /content/TABS/.git/objects/info/\n","   creating: /content/TABS/.git/objects/pack/\n","  inflating: /content/TABS/.git/objects/pack/pack-d9e3911acb5b4cd7f7fe531a5f26a894afdefe9b.idx  \n","  inflating: /content/TABS/.git/objects/pack/pack-d9e3911acb5b4cd7f7fe531a5f26a894afdefe9b.pack  \n","  inflating: /content/TABS/.git/packed-refs  \n","   creating: /content/TABS/.git/refs/\n","   creating: /content/TABS/.git/refs/heads/\n"," extracting: /content/TABS/.git/refs/heads/main  \n","   creating: /content/TABS/.git/refs/remotes/\n","   creating: /content/TABS/.git/refs/remotes/origin/\n"," extracting: /content/TABS/.git/refs/remotes/origin/HEAD  \n","   creating: /content/TABS/.git/refs/tags/\n","   creating: /content/TABS/Models/\n"," extracting: /content/TABS/Models/__init__.py  \n","   creating: /content/TABS/Models/__pycache__/\n","  inflating: /content/TABS/Models/__pycache__/__init__.cpython-312.pyc  \n","  inflating: /content/TABS/Models/__pycache__/PositionalEncoding.cpython-312.pyc  \n","  inflating: /content/TABS/Models/__pycache__/TABS_Model.cpython-312.pyc  \n","  inflating: /content/TABS/Models/__pycache__/Transformer.cpython-312.pyc  \n","  inflating: /content/TABS/Models/PositionalEncoding.py  \n","  inflating: /content/TABS/Models/TABS_Model.py  \n","  inflating: /content/TABS/Models/TABS_Model_2D.py  \n","  inflating: /content/TABS/Models/Transformer.py  \n","  inflating: /content/TABS/README.md  \n","  inflating: /content/TABS/test.py   \n","  inflating: /content/TABS/train.py  \n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/TABS')"],"metadata":{"id":"ooaGy98jxrAJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from monai.transforms import (\n","    Compose, LoadImage, Spacing, NormalizeIntensity, ScaleIntensityRange, CenterSpatialCrop\n",")\n","from torch.utils.data import DataLoader, Dataset\n","import nibabel as nib\n","import numpy as np\n","import os\n","import torch\n","# from TABS.Models.TABS_Model import TABS\n","from monai.losses import DiceCELoss\n","from torch.optim import AdamW\n","from torch.cuda.amp import GradScaler, autocast"],"metadata":{"id":"jW9VU9mZqKhJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hvn2T0ZQCEEb","executionInfo":{"status":"ok","timestamp":1735569985116,"user_tz":-60,"elapsed":255,"user":{"displayName":"Mahdi Islam","userId":"09138204596823341323"}},"outputId":"d281ffca-9802-410d-9d3c-d812f42f4fcc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Dec 30 14:46:25 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0              47W / 400W |      2MiB / 40960MiB |      0%      Default |\n","|                                         |                      |             Disabled |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/MAIA_Work/Semester_3/MISA/MISA_Project/TABS\n","!python train.py --root /content/drive/MyDrive/MAIA_Work/Semester_3/MISA/MISA_Project/TABS --gpu 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wy5s1a-O87Th","executionInfo":{"status":"ok","timestamp":1735741028525,"user_tz":-60,"elapsed":197310,"user":{"displayName":"Mahdi Islam","userId":"09138204596823341323"}},"outputId":"9238bab0-8655-4021-8527-f2e09dc91cda"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/MAIA_Work/Semester_3/MISA/MISA_Project/TABS\n","Using GPU: NVIDIA A100-SXM4-40GB\n","/content/drive/MyDrive/MAIA_Work/Semester_3/MISA/MISA_Project/TABS/train.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(pretrained_weights_path, map_location='cpu')\n","Model Built and Pretrained Weights Loaded!\n","Start to train!\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 0 | Train Loss: 0.0895 | Val Loss: 0.1717 | Pearson: 0.5439 | Dice: [0.04950529411435127, 0.6410425543785095, 0.5890744447708129]\n","saving model at the end of epoch 0\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 1 | Train Loss: 0.0703 | Val Loss: 0.2179 | Pearson: 0.5539 | Dice: [0.05808967724442482, 0.6135085701942444, 0.5558953046798706]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 2 | Train Loss: 0.0703 | Val Loss: 0.2196 | Pearson: 0.5548 | Dice: [0.06426618248224258, 0.629889726638794, 0.5361685514450073]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 3 | Train Loss: 0.0677 | Val Loss: 0.2171 | Pearson: 0.5612 | Dice: [0.06774690076708793, 0.63197420835495, 0.5371605038642884]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 4 | Train Loss: 0.0645 | Val Loss: 0.2166 | Pearson: 0.5613 | Dice: [0.08191193789243698, 0.6266123294830322, 0.5462660551071167]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 5 | Train Loss: 0.0631 | Val Loss: 0.2176 | Pearson: 0.5624 | Dice: [0.09610501080751419, 0.6324083685874939, 0.5444200515747071]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 6 | Train Loss: 0.0616 | Val Loss: 0.2165 | Pearson: 0.5653 | Dice: [0.10228455513715744, 0.6331123232841491, 0.5462496995925903]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 7 | Train Loss: 0.0600 | Val Loss: 0.2160 | Pearson: 0.5671 | Dice: [0.10562163293361664, 0.633911418914795, 0.5485623598098754]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 8 | Train Loss: 0.0586 | Val Loss: 0.2155 | Pearson: 0.5687 | Dice: [0.10422918647527694, 0.6334101557731628, 0.5533321499824524]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 9 | Train Loss: 0.0578 | Val Loss: 0.2162 | Pearson: 0.5668 | Dice: [0.10638405233621598, 0.6309360980987548, 0.5570677876472473]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 10 | Train Loss: 0.0570 | Val Loss: 0.2172 | Pearson: 0.5655 | Dice: [0.10888329148292542, 0.6311270713806152, 0.5592246413230896]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 11 | Train Loss: 0.0566 | Val Loss: 0.2177 | Pearson: 0.5648 | Dice: [0.1136825680732727, 0.63273766040802, 0.5560580372810364]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 12 | Train Loss: 0.0560 | Val Loss: 0.2160 | Pearson: 0.5693 | Dice: [0.11657697707414627, 0.6361436009407043, 0.5536045908927918]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 13 | Train Loss: 0.0550 | Val Loss: 0.2163 | Pearson: 0.5683 | Dice: [0.11862784624099731, 0.6350704431533813, 0.5545026063919067]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 14 | Train Loss: 0.0544 | Val Loss: 0.2165 | Pearson: 0.5685 | Dice: [0.12342704087495804, 0.6353566408157348, 0.5555935502052307]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 15 | Train Loss: 0.0540 | Val Loss: 0.2167 | Pearson: 0.5683 | Dice: [0.12659405022859574, 0.635856282711029, 0.5556768178939819]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 16 | Train Loss: 0.0536 | Val Loss: 0.2165 | Pearson: 0.5689 | Dice: [0.12663453370332717, 0.6354531288146973, 0.5571658968925476]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 17 | Train Loss: 0.0530 | Val Loss: 0.2165 | Pearson: 0.5689 | Dice: [0.12540776580572127, 0.6359155058860779, 0.5572661995887757]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 18 | Train Loss: 0.0526 | Val Loss: 0.2167 | Pearson: 0.5689 | Dice: [0.12724287509918214, 0.6358742594718934, 0.5583286285400391]\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","torch.Size([1, 512, 12, 12, 12])\n","Epoch: 19 | Train Loss: 0.0524 | Val Loss: 0.2167 | Pearson: 0.5690 | Dice: [0.12735578417778015, 0.6361476063728333, 0.558095395565033]\n","The total training time is 0.04 hours\n","----------------------------------The training process finished!-----------------------------------\n"]}]},{"cell_type":"code","source":["# # Image preprocessing pipeline\n","# image_transforms = Compose([\n","#     LoadImage(image_only=True, ensure_channel_first=True),\n","#     Spacing(pixdim=(1.0, 1.0, 1.0), mode='bilinear'),\n","#     CenterSpatialCrop(roi_size=(192, 192, 192)),\n","#     NormalizeIntensity(nonzero=True, channel_wise=True),\n","#     ScaleIntensityRange(a_min=-3.364, a_max=1.81, b_min=-1.0, b_max=1.0, clip=True),\n","# ])\n","\n","# # Label preprocessing pipeline\n","# label_transforms = Compose([\n","#     LoadImage(image_only=True, ensure_channel_first=True),\n","#     Spacing(pixdim=(1.0, 1.0, 1.0), mode='nearest'),\n","#     CenterSpatialCrop(roi_size=(192, 192, 192)),\n","# ])"],"metadata":{"id":"j6vycwIeqYXP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BrainSegmentationDataset(Dataset):\n","    def __init__(self, image_dir, label_dir, transform=None):\n","        \"\"\"\n","        Args:\n","            image_dir (str): Path to the directory containing preprocessed images.\n","            label_dir (str): Path to the directory containing preprocessed labels.\n","            transform (callable, optional): Transform to apply to the data. Defaults to None.\n","        \"\"\"\n","        self.image_dir = image_dir\n","        self.label_dir = label_dir\n","        self.image_filenames = sorted(os.listdir(image_dir))\n","        self.label_filenames = sorted(os.listdir(label_dir))\n","        self.transform = transform\n","\n","        assert len(self.image_filenames) == len(self.label_filenames), \\\n","            \"Number of images and labels must match.\"\n","\n","    def __len__(self):\n","        return len(self.image_filenames)\n","\n","    def __getitem__(self, idx):\n","        # Load the image and label file paths\n","        image_path = os.path.join(self.image_dir, self.image_filenames[idx])\n","        label_path = os.path.join(self.label_dir, self.label_filenames[idx])\n","\n","        # Load image and label data\n","        image = nib.load(image_path).get_fdata().astype(np.float32)  # Shape: (C, D, H, W)\n","        label = nib.load(label_path).get_fdata().astype(np.int64)    # Shape: (C, D, H, W)\n","\n","        # Apply transforms to the image (if any)\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        # Convert to PyTorch tensors\n","        image = torch.tensor(image, dtype=torch.float32)  # Shape: [C, D, H, W]\n","        label = torch.tensor(label, dtype=torch.float32)     # Shape: [C, D, H, W]\n","\n","        return image, label"],"metadata":{"id":"34VRv3KLrO23"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Paths to dataset\n","train_image_dir = \"/content/drive/MyDrive/MAIA_Work/Semester_3/MISA/MISA_Project/ProcessedDataV3/Training_Set/Image\"\n","train_label_dir = \"/content/drive/MyDrive/MAIA_Work/Semester_3/MISA/MISA_Project/ProcessedDataV3/Training_Set/Label_ProbMaps\"\n","\n","# Create Datasets and DataLoaders\n","train_dataset = BrainSegmentationDataset(train_image_dir, train_label_dir)\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)"],"metadata":{"id":"3Gd4K03qrRd6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Paths to dataset\n","valid_image_dir = \"/content/drive/MyDrive/MAIA_Work/Semester_3/MISA/MISA_Project/ProcessedDataV3/Validation_Set/Image\"\n","valid_label_dir = \"/content/drive/MyDrive/MAIA_Work/Semester_3/MISA/MISA_Project/ProcessedDataV3/Validation_Set/Label_ProbMaps\"\n","\n","# Create Datasets and DataLoaders\n","valid_dataset = BrainSegmentationDataset(valid_image_dir, valid_label_dir)\n","valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=True, num_workers=0)"],"metadata":{"id":"dw69hI1Tg7Ci"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example: Iterate through the DataLoader\n","for images, labels in train_loader:\n","    print(f\"Image shape: {images.shape}\")  # (batch_size, 1, 192, 192, 192)\n","    print(f\"Label shape: {labels.shape}\")  # (batch_size, 1, 192, 192, 192)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BtUOMZ7Et-O2","executionInfo":{"status":"ok","timestamp":1735571065144,"user_tz":-60,"elapsed":2731,"user":{"displayName":"Mahdi Islam","userId":"09138204596823341323"}},"outputId":"968b7f38-217e-497d-a1ef-a69776348e17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Image shape: torch.Size([4, 1, 192, 192, 192])\n","Label shape: torch.Size([4, 3, 192, 192, 192])\n"]}]},{"cell_type":"code","source":["# num_epochs = 50\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# # Load the pretrained TABS model\n","# model = TABS()\n","# pretrained_weights_path = '/content/drive/MyDrive/MAIA_Work/Semester_3/MISA/MISA_Project/best_model_TABS.pth'\n","# checkpoint = torch.load(pretrained_weights_path, map_location=device)\n","# model.load_state_dict(checkpoint['state_dict'])  # Adjust if checkpoint key differs\n","# model.to(device)\n","\n","# # Optimizer, scaler, and loss function\n","# optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n","# scaler = GradScaler()\n","# criterion = DiceCELoss(include_background=False, softmax=True)  # Use your preferred loss function"],"metadata":{"id":"sVIvudZcyBYB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for epoch in range(num_epochs):\n","#     model.train()\n","#     train_loss = 0\n","\n","#     for images, labels in train_loader:\n","#         images, labels = images.to(device), labels.to(device)\n","\n","#         # Ensure labels are in correct format\n","#         labels = labels.squeeze(1)  # [batch_size, D, H, W]\n","\n","#         optimizer.zero_grad()\n","#         with autocast(device_type='cuda'):\n","#             outputs = model(images)  # [batch_size, num_classes, D, H, W]\n","#             loss = criterion(outputs, labels)\n","\n","#         scaler.scale(loss).backward()\n","#         scaler.step(optimizer)\n","#         scaler.update()\n","\n","#         train_loss += loss.item()\n","\n","#     avg_train_loss = train_loss / len(train_loader)\n","#     print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}\")\n","\n","#     # Save model checkpoint\n","#     checkpoint_path = f\"/content/drive/MyDrive/MAIA_Work/Semester_3/MISA/MISA_Project/TABS_finetuned_epoch_{epoch+1}.pth\"\n","#     torch.save({'state_dict': model.state_dict()}, checkpoint_path)\n","#     print(f\"Saved checkpoint: {checkpoint_path}\")\n"],"metadata":{"id":"ByHwraKPuWmC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# val_image_dir = \"ProcessedDataV3/Validation_Set/Image\"\n","# val_label_dir = \"ProcessedDataV3/Validation_Set/Label\"\n","\n","# val_dataset = BrainSegmentationDataset(val_image_dir, val_label_dir)\n","# val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2)\n","\n","# model.eval()\n","# val_loss = 0\n","# with torch.no_grad():\n","#     for images, labels in val_loader:\n","#         images, labels = images.to(device), labels.to(device)\n","#         with autocast():\n","#             outputs = model(images)\n","#             loss = criterion(outputs, labels)\n","#         val_loss += loss.item()\n","\n","# avg_val_loss = val_loss / len(val_loader)\n","# print(f\"Validation Loss: {avg_val_loss:.4f}\")\n"],"metadata":{"id":"OFHrmBD2y-Vq"},"execution_count":null,"outputs":[]}]}